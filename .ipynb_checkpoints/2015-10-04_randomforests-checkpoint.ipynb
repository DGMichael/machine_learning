{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Machine Learning: Decision Trees\n",
    "Construction of a random forest to classify phone data into activity phases.  \n",
    "Using the UCI Machine Learning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-09-09_train_test_split.ipynb  2015-10-04_randomforests.ipynb     UCI HAR Dataset.zip\r\n",
      "2015-09-13_overfitting.py.ipynb    README.md                          random_forest.py\r\n",
      "2015-09-17_cross_validation.ipynb  \u001b[34mUCI HAR Dataset\u001b[m\u001b[m/                   sampleData.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt           \u001b[31mactivity_labels.txt\u001b[m\u001b[m* \u001b[31mfeatures.txt\u001b[m\u001b[m*        \u001b[31mfeatures_info.txt\u001b[m\u001b[m*   \u001b[34mtest\u001b[m\u001b[m/                \u001b[34mtrain\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load features names:\n",
    "import pandas as pd\n",
    "features_df = pd.read_csv('features.txt', sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>tBodyAcc-mean()-Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>tBodyAcc-mean()-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>tBodyAcc-std()-X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>tBodyAcc-std()-Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>tBodyAcc-std()-Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  tBodyAcc-mean()-X\n",
       "0  2  tBodyAcc-mean()-Y\n",
       "1  3  tBodyAcc-mean()-Z\n",
       "2  4   tBodyAcc-std()-X\n",
       "3  5   tBodyAcc-std()-Y\n",
       "4  6   tBodyAcc-std()-Z"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the features:\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 662 fields in line 27, saw 665\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-539ec3e0c698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/X_train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7544)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:7784)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:8401)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:8275)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:20691)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 662 fields in line 27, saw 665\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"train/X_train.txt\", sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/mdrew/thinkful/machine_learning'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#^ THAT COMPLETELY FAILS.\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble as sk\n",
    "import pylab as pl\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "\n",
    "xt = []\n",
    "yt = []\n",
    "features = []\n",
    "activity = {1: \"walking\", 2: \"walking_upstairs\", 3: \"walking_downstairs\",\n",
    "            4: \"sitting\", 5: \"standing\", 6: \"laying\"}\n",
    "c = []\n",
    "feat = open('UCI HAR Dataset/features.txt', 'r')\n",
    "for i, r in enumerate(feat):\n",
    "    c.append(\"x\" + str(i))\n",
    "    features.append(r.split()[1])\n",
    "\n",
    "dex = []\n",
    "subj = open('UCI HAR Dataset/train/subject_train.txt', 'r')\n",
    "for line in subj:\n",
    "    dex.append(int(line))\n",
    "xtrain = open('UCI HAR Dataset/train/X_train.txt', 'r')\n",
    "for line in xtrain:\n",
    "    # df.loc[i] = np.array([line.rstrip().split()])\n",
    "    xt.append(map(lambda x: float(x), line.split()))\n",
    "\n",
    "ytrain = open('UCI HAR Dataset/train/y_train.txt', 'r')\n",
    "for line in ytrain:\n",
    "    yt.append(activity[int(line.rstrip())])\n",
    "df = pd.DataFrame(xt, columns=c)\n",
    "df['p_ID'] = dex\n",
    "df['activity'] = yt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x553</th>\n",
       "      <th>x554</th>\n",
       "      <th>x555</th>\n",
       "      <th>x556</th>\n",
       "      <th>x557</th>\n",
       "      <th>x558</th>\n",
       "      <th>x559</th>\n",
       "      <th>x560</th>\n",
       "      <th>p_ID</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
       "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
       "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
       "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
       "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
       "\n",
       "         x7        x8        x9    ...         x553      x554      x555  \\\n",
       "0 -0.983185 -0.923527 -0.934724    ...    -0.710304 -0.112754  0.030400   \n",
       "1 -0.974914 -0.957686 -0.943068    ...    -0.861499  0.053477 -0.007435   \n",
       "2 -0.963668 -0.977469 -0.938692    ...    -0.760104 -0.118559  0.177899   \n",
       "3 -0.982750 -0.989302 -0.938692    ...    -0.482845 -0.036788 -0.012892   \n",
       "4 -0.979672 -0.990441 -0.942469    ...    -0.699205  0.123320  0.122542   \n",
       "\n",
       "       x556      x557      x558      x559      x560  p_ID  activity  \n",
       "0 -0.464761 -0.018446 -0.841247  0.179941 -0.058627     1  standing  \n",
       "1 -0.732626  0.703511 -0.844788  0.180289 -0.054317     1  standing  \n",
       "2  0.100699  0.808529 -0.848933  0.180637 -0.049118     1  standing  \n",
       "3  0.640011 -0.485366 -0.848649  0.181935 -0.047663     1  standing  \n",
       "4  0.693578 -0.615971 -0.847865  0.185151 -0.043892     1  standing  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = df.loc[df['p_ID'] >= 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feat = training_set.columns[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'x0', u'x1', u'x2', u'x3', u'x4', u'x5', u'x6', u'x7', u'x8', u'x9', \n",
       "       ...\n",
       "       u'x551', u'x552', u'x553', u'x554', u'x555', u'x556', u'x557', u'x558',\n",
       "       u'x559', u'x560'],\n",
       "      dtype='object', length=561)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = training_set[train_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x551</th>\n",
       "      <th>x552</th>\n",
       "      <th>x553</th>\n",
       "      <th>x554</th>\n",
       "      <th>x555</th>\n",
       "      <th>x556</th>\n",
       "      <th>x557</th>\n",
       "      <th>x558</th>\n",
       "      <th>x559</th>\n",
       "      <th>x560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>0.278791</td>\n",
       "      <td>-0.032477</td>\n",
       "      <td>-0.145829</td>\n",
       "      <td>-0.993050</td>\n",
       "      <td>-0.938822</td>\n",
       "      <td>-0.928840</td>\n",
       "      <td>-0.993505</td>\n",
       "      <td>-0.935597</td>\n",
       "      <td>-0.916592</td>\n",
       "      <td>-0.937860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469190</td>\n",
       "      <td>-0.807955</td>\n",
       "      <td>-0.939560</td>\n",
       "      <td>-0.051193</td>\n",
       "      <td>0.102632</td>\n",
       "      <td>0.066183</td>\n",
       "      <td>0.944358</td>\n",
       "      <td>-0.838642</td>\n",
       "      <td>0.209054</td>\n",
       "      <td>0.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>0.275709</td>\n",
       "      <td>-0.017983</td>\n",
       "      <td>-0.102424</td>\n",
       "      <td>-0.995569</td>\n",
       "      <td>-0.981350</td>\n",
       "      <td>-0.978256</td>\n",
       "      <td>-0.995906</td>\n",
       "      <td>-0.981642</td>\n",
       "      <td>-0.981780</td>\n",
       "      <td>-0.942066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270056</td>\n",
       "      <td>-0.586514</td>\n",
       "      <td>-0.844675</td>\n",
       "      <td>0.099949</td>\n",
       "      <td>-0.033375</td>\n",
       "      <td>0.629909</td>\n",
       "      <td>0.409820</td>\n",
       "      <td>-0.830250</td>\n",
       "      <td>0.215456</td>\n",
       "      <td>0.014507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>0.277683</td>\n",
       "      <td>-0.021163</td>\n",
       "      <td>-0.107035</td>\n",
       "      <td>-0.995089</td>\n",
       "      <td>-0.982616</td>\n",
       "      <td>-0.985356</td>\n",
       "      <td>-0.996059</td>\n",
       "      <td>-0.983539</td>\n",
       "      <td>-0.985157</td>\n",
       "      <td>-0.934012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243723</td>\n",
       "      <td>-0.480027</td>\n",
       "      <td>-0.818973</td>\n",
       "      <td>-0.108542</td>\n",
       "      <td>0.221648</td>\n",
       "      <td>0.784523</td>\n",
       "      <td>-0.281809</td>\n",
       "      <td>-0.829194</td>\n",
       "      <td>0.216168</td>\n",
       "      <td>0.013870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>0.277301</td>\n",
       "      <td>-0.015994</td>\n",
       "      <td>-0.098619</td>\n",
       "      <td>-0.994266</td>\n",
       "      <td>-0.978326</td>\n",
       "      <td>-0.976918</td>\n",
       "      <td>-0.995092</td>\n",
       "      <td>-0.978368</td>\n",
       "      <td>-0.975008</td>\n",
       "      <td>-0.934012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294119</td>\n",
       "      <td>-0.480123</td>\n",
       "      <td>-0.753174</td>\n",
       "      <td>0.033209</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>0.878145</td>\n",
       "      <td>-0.952204</td>\n",
       "      <td>-0.827296</td>\n",
       "      <td>0.217438</td>\n",
       "      <td>0.012735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>0.279601</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>-0.090564</td>\n",
       "      <td>-0.995235</td>\n",
       "      <td>-0.987974</td>\n",
       "      <td>-0.989725</td>\n",
       "      <td>-0.995816</td>\n",
       "      <td>-0.988687</td>\n",
       "      <td>-0.989033</td>\n",
       "      <td>-0.940833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394216</td>\n",
       "      <td>-0.721772</td>\n",
       "      <td>-0.921732</td>\n",
       "      <td>-0.013611</td>\n",
       "      <td>-0.501153</td>\n",
       "      <td>0.860905</td>\n",
       "      <td>-0.182502</td>\n",
       "      <td>-0.827697</td>\n",
       "      <td>0.217023</td>\n",
       "      <td>0.009989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2        x3        x4        x5        x6  \\\n",
       "5867  0.278791 -0.032477 -0.145829 -0.993050 -0.938822 -0.928840 -0.993505   \n",
       "5868  0.275709 -0.017983 -0.102424 -0.995569 -0.981350 -0.978256 -0.995906   \n",
       "5869  0.277683 -0.021163 -0.107035 -0.995089 -0.982616 -0.985356 -0.996059   \n",
       "5870  0.277301 -0.015994 -0.098619 -0.994266 -0.978326 -0.976918 -0.995092   \n",
       "5871  0.279601 -0.013969 -0.090564 -0.995235 -0.987974 -0.989725 -0.995816   \n",
       "\n",
       "            x7        x8        x9    ...         x551      x552      x553  \\\n",
       "5867 -0.935597 -0.916592 -0.937860    ...     0.469190 -0.807955 -0.939560   \n",
       "5868 -0.981642 -0.981780 -0.942066    ...     0.270056 -0.586514 -0.844675   \n",
       "5869 -0.983539 -0.985157 -0.934012    ...     0.243723 -0.480027 -0.818973   \n",
       "5870 -0.978368 -0.975008 -0.934012    ...     0.294119 -0.480123 -0.753174   \n",
       "5871 -0.988687 -0.989033 -0.940833    ...     0.394216 -0.721772 -0.921732   \n",
       "\n",
       "          x554      x555      x556      x557      x558      x559      x560  \n",
       "5867 -0.051193  0.102632  0.066183  0.944358 -0.838642  0.209054  0.005301  \n",
       "5868  0.099949 -0.033375  0.629909  0.409820 -0.830250  0.215456  0.014507  \n",
       "5869 -0.108542  0.221648  0.784523 -0.281809 -0.829194  0.216168  0.013870  \n",
       "5870  0.033209  0.391622  0.878145 -0.952204 -0.827296  0.217438  0.012735  \n",
       "5871 -0.013611 -0.501153  0.860905 -0.182502 -0.827697  0.217023  0.009989  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y= training_set['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5867    standing\n",
       "5868    standing\n",
       "5869    standing\n",
       "5870    standing\n",
       "5871    standing\n",
       "Name: activity, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate the estimator object, using out of bag sampling for score estimation\n",
    "rf = sk.RandomForestClassifier(n_estimators=50, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the RF estimator to X and y DF:\n",
    "rf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99124579124579126"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF OOB Score:\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__len__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_get_param_names',\n",
       " '_make_estimator',\n",
       " '_set_oob_score',\n",
       " '_validate_estimator',\n",
       " '_validate_y_class_weight',\n",
       " 'apply',\n",
       " 'base_estimator',\n",
       " 'base_estimator_',\n",
       " 'bootstrap',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'criterion',\n",
       " 'estimator_params',\n",
       " 'estimators_',\n",
       " 'feature_importances_',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_leaf_nodes',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'n_classes_',\n",
       " 'n_estimators',\n",
       " 'n_features_',\n",
       " 'n_jobs',\n",
       " 'n_outputs_',\n",
       " 'oob_decision_function_',\n",
       " 'oob_score',\n",
       " 'oob_score_',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = df.loc[df['p_ID'] <= 6]\n",
    "testX = test_set[train_feat]\n",
    "testY = test_set['activity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy score for the RF model on test data:  0.828897338403\n",
      "test (prediction):  ['standing' 'standing' 'standing' ..., 'walking_downstairs'\n",
      " 'walking_downstairs' 'walking_downstairs']\n"
     ]
    }
   ],
   "source": [
    "print \"mean accuracy score for the RF model on test data: \", rf.score(\n",
    "    testX, testY)\n",
    "print \"test (prediction): \", rf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.87400422e-04,   1.10177243e-04,   2.30896207e-04,\n",
       "         4.20677997e-03,   3.11452649e-05,   4.08375165e-03,\n",
       "         3.55447445e-03,   5.20277350e-05,   5.85867104e-04,\n",
       "         5.52663774e-03,   8.30477986e-05,   7.46833451e-04,\n",
       "         5.41978038e-05,   4.40127525e-05,   6.74786177e-04,\n",
       "         4.08040471e-03,   7.50769597e-03,   0.00000000e+00,\n",
       "         4.14816613e-04,   4.86314053e-03,   2.03558132e-04,\n",
       "         3.57066168e-04,   2.49939496e-03,   3.47849845e-04,\n",
       "         0.00000000e+00,   1.12527401e-04,   8.12766612e-06,\n",
       "         0.00000000e+00,   3.15868568e-05,   1.98884336e-04,\n",
       "         5.56566193e-05,   3.30609318e-05,   1.27666051e-04,\n",
       "         5.81487049e-04,   9.53596213e-05,   6.03603854e-05,\n",
       "         4.08515019e-05,   1.24413570e-02,   1.46794887e-03,\n",
       "         3.54761095e-03,   1.54174217e-02,   8.93438597e-03,\n",
       "         2.17813474e-02,   3.36211723e-04,   1.43749083e-03,\n",
       "         1.52288984e-04,   1.88432206e-03,   2.09019628e-03,\n",
       "         2.49465485e-04,   8.61178649e-03,   1.04278062e-02,\n",
       "         2.08363715e-02,   2.74079464e-02,   1.85667653e-02,\n",
       "         2.29011423e-02,   9.79644928e-03,   1.98707880e-02,\n",
       "         1.19049240e-02,   4.20276134e-02,   4.19019515e-04,\n",
       "         4.65478789e-04,   2.16185290e-05,   7.18827243e-03,\n",
       "         1.58528640e-03,   2.66655592e-04,   3.18753806e-03,\n",
       "         2.58269903e-03,   2.99297563e-04,   2.04653661e-04,\n",
       "         3.18374882e-03,   1.05430518e-03,   8.01597246e-04,\n",
       "         5.80956614e-04,   5.97157029e-03,   9.44893840e-03,\n",
       "         6.00476816e-03,   5.50027933e-03,   4.88530682e-04,\n",
       "         1.30139767e-03,   1.74926673e-03,   7.33361514e-05,\n",
       "         4.84733766e-05,   4.03425945e-05,   1.00555489e-02,\n",
       "         3.21326387e-05,   5.70636020e-03,   3.82954550e-03,\n",
       "         6.45635852e-04,   1.24143955e-04,   8.46377079e-03,\n",
       "         1.11784701e-03,   5.68001290e-03,   4.21100904e-03,\n",
       "         4.31909512e-04,   4.46347448e-04,   3.08716608e-05,\n",
       "         1.99476233e-03,   1.93004835e-03,   1.80730478e-03,\n",
       "         1.75625827e-03,   1.32262049e-03,   2.76836576e-04,\n",
       "         9.55970675e-04,   9.28707171e-05,   3.54605291e-04,\n",
       "         1.77674158e-04,   2.16363412e-05,   1.59775649e-04,\n",
       "         2.30123933e-04,   2.00405959e-04,   0.00000000e+00,\n",
       "         3.55520371e-04,   1.79855967e-04,   3.24226515e-04,\n",
       "         6.43416218e-05,   4.26569098e-05,   6.02873736e-05,\n",
       "         2.47353708e-03,   1.99732471e-03,   1.31000960e-04,\n",
       "         4.24436947e-04,   5.06196525e-05,   3.91658781e-04,\n",
       "         2.18702830e-03,   1.26433367e-04,   8.29640371e-03,\n",
       "         1.88587140e-03,   8.03498162e-03,   8.26798505e-03,\n",
       "         2.80352448e-03,   0.00000000e+00,   4.03825188e-04,\n",
       "         2.48032040e-04,   3.18422331e-04,   1.31749506e-04,\n",
       "         4.12253679e-03,   4.87442891e-04,   5.91678360e-05,\n",
       "         1.26450815e-03,   3.39744001e-03,   4.16831166e-03,\n",
       "         3.94368780e-04,   1.12089735e-03,   1.39675144e-04,\n",
       "         2.66473555e-04,   9.90156380e-04,   2.59335986e-05,\n",
       "         1.38999054e-04,   2.06956905e-04,   1.39864410e-04,\n",
       "         2.24246583e-04,   4.76040812e-04,   5.50697318e-05,\n",
       "         9.44552611e-05,   2.34041875e-04,   1.82718599e-04,\n",
       "         1.38188415e-04,   8.94551686e-04,   4.42176221e-04,\n",
       "         7.20947020e-04,   1.43771875e-04,   1.31573430e-04,\n",
       "         3.09808033e-04,   1.10877822e-03,   7.19918235e-05,\n",
       "         4.58326946e-03,   5.17019107e-03,   6.79453377e-04,\n",
       "         2.42837740e-03,   2.30975882e-03,   1.55629047e-04,\n",
       "         0.00000000e+00,   2.59856028e-03,   1.16389520e-04,\n",
       "         5.65824248e-04,   4.27495968e-04,   2.01008685e-03,\n",
       "         6.87609409e-05,   1.02913314e-02,   3.48933075e-03,\n",
       "         3.95671841e-03,   1.73600078e-03,   2.92970306e-03,\n",
       "         1.96783941e-04,   2.78495592e-05,   1.27120019e-03,\n",
       "         2.05155901e-04,   4.05713645e-04,   6.35065839e-05,\n",
       "         1.77566330e-04,   1.31098429e-04,   1.80058615e-04,\n",
       "         4.82815242e-05,   5.41671693e-04,   5.00575996e-04,\n",
       "         1.68651036e-04,   6.47327325e-04,   8.17568374e-04,\n",
       "         1.15844337e-03,   3.58076836e-04,   3.89893829e-05,\n",
       "         5.68343092e-03,   8.94544730e-03,   5.68869421e-04,\n",
       "         2.14882073e-04,   3.23049365e-05,   3.23226574e-05,\n",
       "         1.66674404e-03,   4.88704322e-04,   2.25317883e-03,\n",
       "         8.17180027e-04,   8.48502145e-05,   9.03962877e-05,\n",
       "         1.28946520e-02,   6.52300731e-03,   3.67593450e-03,\n",
       "         3.91034512e-03,   6.06546929e-05,   2.64431470e-04,\n",
       "         6.66243215e-03,   0.00000000e+00,   4.02364313e-03,\n",
       "         3.10093901e-04,   1.11784470e-03,   5.73659135e-05,\n",
       "         0.00000000e+00,   3.97551354e-03,   5.18323463e-04,\n",
       "         1.09994216e-04,   0.00000000e+00,   1.72224186e-05,\n",
       "         4.36083101e-03,   4.21962963e-03,   1.02599642e-04,\n",
       "         4.28169198e-03,   3.47531424e-04,   3.77910735e-04,\n",
       "         1.33253769e-04,   3.88599697e-04,   3.10584931e-05,\n",
       "         1.10171365e-04,   3.22876087e-05,   0.00000000e+00,\n",
       "         8.38941234e-05,   7.07381642e-05,   4.12754506e-03,\n",
       "         4.63438430e-04,   6.16401879e-05,   1.62950338e-04,\n",
       "         1.26567844e-04,   2.78768700e-04,   1.51207751e-04,\n",
       "         2.19541264e-04,   4.74407839e-04,   6.79140339e-04,\n",
       "         7.98717276e-05,   2.43031196e-05,   4.25161710e-03,\n",
       "         2.63612202e-04,   1.06146360e-04,   0.00000000e+00,\n",
       "         1.16808156e-04,   1.22714994e-04,   1.23796436e-04,\n",
       "         3.17823850e-05,   8.37391261e-03,   2.88057716e-05,\n",
       "         0.00000000e+00,   6.56554352e-03,   0.00000000e+00,\n",
       "         5.17797976e-04,   2.65309638e-04,   2.45209755e-04,\n",
       "         4.86893244e-05,   6.35058272e-03,   1.87304058e-04,\n",
       "         1.16641720e-03,   7.16494931e-05,   2.50851785e-04,\n",
       "         1.14122646e-04,   1.64361338e-03,   4.17576250e-03,\n",
       "         0.00000000e+00,   1.07240906e-03,   2.05903175e-04,\n",
       "         2.70420873e-05,   9.97356387e-04,   4.14267226e-03,\n",
       "         1.06476235e-04,   1.51451999e-04,   8.00127084e-04,\n",
       "         0.00000000e+00,   6.72819431e-04,   1.61119133e-03,\n",
       "         6.26507897e-05,   1.02472664e-03,   2.62363669e-03,\n",
       "         1.74355805e-03,   1.76020815e-03,   7.60142521e-04,\n",
       "         2.70396647e-05,   5.00638398e-04,   4.61505683e-03,\n",
       "         4.54403055e-03,   3.06858394e-04,   7.62470807e-05,\n",
       "         5.94570319e-05,   2.78082163e-05,   4.86179621e-05,\n",
       "         1.51744181e-04,   1.31196535e-02,   1.22833884e-04,\n",
       "         8.78443143e-05,   2.04702507e-04,   5.87136203e-03,\n",
       "         0.00000000e+00,   9.79598632e-04,   0.00000000e+00,\n",
       "         1.84476891e-04,   1.62614212e-04,   1.58315776e-04,\n",
       "         2.27556618e-04,   7.27983206e-05,   4.81282926e-04,\n",
       "         1.34814143e-04,   5.85765969e-05,   8.31569846e-05,\n",
       "         8.14503726e-05,   0.00000000e+00,   7.21903362e-04,\n",
       "         1.12615078e-04,   1.13587100e-03,   5.30583853e-03,\n",
       "         4.03208281e-04,   2.44454599e-04,   5.79653142e-05,\n",
       "         1.63992533e-04,   1.50229039e-04,   1.59136476e-04,\n",
       "         2.88117271e-03,   4.73374007e-05,   3.60133053e-05,\n",
       "         3.96920137e-03,   2.73460780e-03,   5.80625230e-03,\n",
       "         6.30623044e-04,   3.15788505e-03,   4.28364438e-03,\n",
       "         4.37701345e-03,   3.92471083e-03,   0.00000000e+00,\n",
       "         2.01265305e-04,   5.47244379e-03,   2.16336699e-05,\n",
       "         6.87040471e-05,   5.64760553e-04,   1.92862106e-05,\n",
       "         9.65907819e-06,   1.70233267e-04,   7.71823179e-04,\n",
       "         1.88554880e-03,   1.37427596e-04,   1.32401538e-02,\n",
       "         9.80627427e-05,   1.11734723e-04,   2.16123937e-05,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.95823086e-03,\n",
       "         5.49034014e-05,   2.97054179e-05,   3.53293612e-03,\n",
       "         6.87620040e-05,   9.74120287e-05,   1.14152622e-04,\n",
       "         3.61091667e-05,   5.12689371e-05,   9.24352592e-05,\n",
       "         2.49163236e-04,   3.92843263e-04,   1.40370078e-04,\n",
       "         2.88604659e-04,   1.38835617e-04,   4.15235856e-04,\n",
       "         6.15812065e-05,   3.22986011e-05,   2.60002035e-05,\n",
       "         0.00000000e+00,   6.50165563e-05,   2.62924865e-03,\n",
       "         8.66794862e-05,   5.52156744e-04,   5.85390852e-05,\n",
       "         8.56778146e-03,   9.63592694e-05,   4.69681353e-04,\n",
       "         2.19914381e-04,   3.28298279e-03,   1.44481744e-04,\n",
       "         9.61556912e-05,   6.30402333e-05,   9.27559094e-05,\n",
       "         5.35210175e-05,   3.06698455e-04,   2.01072853e-04,\n",
       "         6.17971040e-04,   1.62097376e-05,   8.35907037e-05,\n",
       "         5.26873985e-05,   4.55409832e-04,   2.57876560e-03,\n",
       "         3.89601505e-03,   7.65812521e-05,   8.37567894e-05,\n",
       "         6.33854229e-05,   3.63028646e-04,   6.18313662e-05,\n",
       "         1.02166936e-04,   4.56096669e-03,   2.06961362e-03,\n",
       "         2.33242068e-04,   3.34854557e-03,   5.52694529e-03,\n",
       "         1.38582407e-03,   6.08663100e-05,   6.49268404e-05,\n",
       "         7.86806484e-04,   4.06300122e-03,   4.58533901e-03,\n",
       "         1.58588401e-03,   6.34773095e-04,   3.43306682e-04,\n",
       "         4.45314116e-03,   1.07204921e-03,   2.37253315e-04,\n",
       "         2.15874351e-04,   2.79948074e-06,   5.66891160e-04,\n",
       "         4.17259551e-03,   6.71527620e-04,   1.92571949e-04,\n",
       "         3.65281626e-04,   7.09441189e-04,   1.92275447e-04,\n",
       "         2.89109266e-04,   3.23922955e-03,   2.92913425e-04,\n",
       "         5.44778877e-05,   3.76848775e-05,   2.28248519e-04,\n",
       "         6.84451819e-03,   1.31579956e-03,   7.56008215e-05,\n",
       "         9.37512832e-05,   6.11309430e-04,   2.54567143e-04,\n",
       "         5.20599391e-04,   1.08510024e-04,   1.35003980e-03,\n",
       "         3.51167735e-04,   7.98073565e-04,   2.50287194e-03,\n",
       "         4.79554315e-04,   8.44150034e-05,   7.50013466e-04,\n",
       "         5.24111083e-04,   1.36151737e-04,   1.17112646e-04,\n",
       "         3.37404391e-03,   8.79912628e-04,   1.37169244e-03,\n",
       "         6.30165442e-04,   2.13373766e-03,   7.32887579e-04,\n",
       "         6.28853195e-04,   4.31168664e-03,   0.00000000e+00,\n",
       "         6.08931987e-05,   1.04029842e-04,   1.11549479e-04,\n",
       "         5.20188268e-06,   4.00808227e-04,   3.74311293e-04,\n",
       "         1.11241490e-04,   1.67018766e-04,   3.52851528e-05,\n",
       "         4.44834162e-04,   2.79090940e-04,   8.66349083e-03,\n",
       "         1.97222868e-04,   2.12933862e-04,   3.70117433e-04,\n",
       "         7.80988924e-05,   1.25105579e-04,   1.08785393e-04,\n",
       "         3.82268545e-04,   1.87115984e-03,   2.80422332e-04,\n",
       "         1.11259786e-04,   9.52700904e-05,   1.12466943e-03,\n",
       "         1.54093466e-05,   5.73720174e-03,   7.11867073e-03,\n",
       "         7.88380355e-03,   2.89306628e-03,   1.41999199e-04,\n",
       "         5.89609359e-04,   1.02601866e-02,   7.15432458e-03,\n",
       "         4.85768107e-04,   7.85784837e-05,   2.40384724e-04,\n",
       "         2.91637436e-05,   7.29954515e-05,   8.73696080e-05,\n",
       "         3.14520257e-04,   1.92147721e-04,   2.94500194e-04,\n",
       "         3.19910787e-05,   5.89810693e-05,   0.00000000e+00,\n",
       "         3.25412052e-05,   6.81900926e-05,   1.45598662e-04,\n",
       "         1.64916001e-04,   3.19195467e-05,   2.70224827e-05,\n",
       "         5.56737816e-05,   5.98571826e-05,   3.11888457e-05,\n",
       "         1.10891351e-04,   1.63820738e-04,   0.00000000e+00,\n",
       "         3.26448955e-04,   3.22270876e-05,   0.00000000e+00,\n",
       "         0.00000000e+00,   6.35177450e-04,   1.46588675e-04,\n",
       "         3.10899938e-05,   1.75549655e-04,   8.41555627e-04,\n",
       "         2.37105577e-04,   2.59295798e-05,   1.47930859e-04,\n",
       "         1.55741952e-04,   2.31522750e-03,   4.32565639e-05,\n",
       "         0.00000000e+00,   7.42757825e-04,   4.32490523e-05,\n",
       "         2.63017365e-04,   2.10714032e-05,   4.72771113e-05,\n",
       "         8.36782956e-05,   2.83946442e-05,   1.16355657e-03,\n",
       "         2.95151564e-02,   2.15063573e-02,   1.47676268e-02])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Importances:\n",
    "rf.feature_importances_\n",
    "#Long list of features with some sort of score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top %s features in the random forest model:10\n",
      "[('tGravityAcc-mean()-X', 0.015417421718403301), ('tGravityAcc-mean()-Z', 0.021781347403762107), ('tGravityAcc-max()-Z', 0.02083637152503116), ('tGravityAcc-min()-X', 0.027407946369494191), ('tGravityAcc-min()-Y', 0.018566765311615458), ('tGravityAcc-min()-Z', 0.022901142329400388), ('tGravityAcc-energy()-X', 0.019870787967246686), ('tGravityAcc-energy()-Z', 0.0420276133924357), ('angle(X,gravityMean)', 0.029515156383825847), ('angle(Y,gravityMean)', 0.021506357297663228)]\n"
     ]
    }
   ],
   "source": [
    "for n in range(50):\n",
    "    z = (n+1)/1000.0 + .010\n",
    "    important_features = [(features[i], n)\n",
    "                          for i, n in enumerate(rf.feature_importances_)\n",
    "                          if n >= z]\n",
    "    if len(important_features) <= 10:\n",
    "        print \"the top %s features in the random forest model:{0}\".format(\n",
    "            len(important_features))\n",
    "        print important_features\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.00028740042150035111, 'tBodyAcc-iqr()-X'),\n",
       " (0.00011017724343520548, 'tBodyAcc-energy()-X'),\n",
       " (0.00023089620677668957, 'tBodyAcc-sma()'),\n",
       " (0.0042067799728886489, 'tBodyAcc-max()-X'),\n",
       " (3.1145264855226164e-05, 'tBodyAcc-mad()-X'),\n",
       " (0.0040837516492555452, 'tBodyAcc-std()-Z'),\n",
       " (0.0035544744489390966, 'tBodyAcc-std()-X'),\n",
       " (5.2027734987009468e-05, 'angle(X,gravityMean)'),\n",
       " (0.000585867103855305, 'angle(Y,gravityMean)'),\n",
       " (0.0055266377393529183, 'angle(Z,gravityMean)')]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THIS TOTALLY FAILS TOO:\n",
    "\n",
    "#Attempt top 10 feature extraction using argpartition fn:\n",
    "import numpy as np\n",
    "type(rf.feature_importances_)\n",
    "indices = np.argpartition(rf.feature_importances_,10)[-10:]\n",
    "top_features = [features[index] for index in indices]\n",
    "ziplist = zip(rf.feature_importances_, top_features)\n",
    "temp_list = sorted(ziplist,reverse=True)\n",
    "ziplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score for the test set:  0.841064638783\n",
      "Mean accuracy score for validation set:  0.826639892905\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD0CAYAAACo2tvDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF45JREFUeJzt3XuYHFWZx/HvJCF3SYBISELMYAQFVsVbUFAZVvFJIoKu\ni4rXwLro4ro8uLgScCFxBcQVEBVcISQPYAC5LIorGlAzCHLHcA2BJBAlJIQQwi0hyWRm9o/3NF3d\n6Uv16a6uUzW/z/PUM93V1VWnp/utc+pU1XlBRERERERERERERERERBIyAvg18ALwiybW8zlgUUtK\nlL4PAMs83/tm4H7gJeBfW1aidHQCfcCglMuRa58F7gVeBtYANwIHt2C9XwDuYuB8eX3AGxNc/yXA\nOS1c3xzg8hatq9HP3kn8wO4Cnmq8SNnVioD5BnAe8F1gd2AycAFwRAvWPQV4HPsCB4qOGq8NaXLd\nU4Clnu8d3OS246j12YMyHPqJPz2fUjG9jcFq6U/WWGYY8EPgaTedBwx1r3UBq7Gdwzqstp/lXpsL\nbAW2uW0cy441RCele+1ZwEqsqfkE1pIozL818r6DgHuwJv7dwPsir3UD3wFuc+tZBOxW5bMVyv9N\n4FlX/o8DM7Ed0gbg5Mjy04A7gI1u2R8DO7nX/uQ+yyvu8x4VWf9/AGuBSymtfaa6bbzDPZ8IrAc+\nWKGsfwS2A6+6z/Um7Pu7zJV9FXAqxeCaBfwZOBd4zv1PoqZT+v0scfPHYC2DNa7s/0Xx+3kTcAv2\nf18PXFnjs5cbBPzAvW8l8DVKv/tjsJ3WS+7149z8Ue4z97p1vwTsQe3vIo7+78acsClTpgM91K75\nvwPcDoxz058p/ki63PvnYDXCDGAT9uMAOB374RF5Xi2wRwEvAnu718YD+7nHsygG9q7Yl/k5977P\nYHvUXdzr3cBy7Ec4HFgMnFXlsxXK/21X/i9jQbDQlWc/YDNWUwK8E/tBDaJYe54QWV95c7Sw/rOw\nH91wdmxWfhl4BOuPWAR8v0pZcZ/l2Mjzy4DrXVmnAI9FXp/ltv01V97hFdZX/v3g1vdTV57XY4dS\nhSC7EpjtHg/FdrAF9ZriXwUeBSZh39ViLFgLv72ZwF7u8Qex31Fhh3cIOzbF630X9fSfHXMihcBu\ntim+G/ZDrtVU/iwWyM+5aS527FzQ417vBX6L7bXf7F7roLR5Vq+p1ge8FftRraNys/Oj2A94oVv+\nKqwzqnDo0A8sAFYAW4CrgQNqbLMHOMOV/xfYjuOH2A9rqZsK7/8L1kLoA/4KXIT96Op9ptPddrZU\neH2eK+vd2M7s1DrrK/wPBwOfxgJtkyvPOZR+N2uww6q+Ktsu/37GYzvnE7Facj32v/iMe30btjOe\n5B7fXqesUZ/CWntPYzvmM8u2fSPwpHv8J+AmrKMRKv9ufL6LEkNiTmloNrA3YLVwrfVMxP5xBX9z\n86LriO4YNgOjPcqyCfuhfhX7Qf4fxR1EeXn+Vjbvr2Vleiby+NU65dlAcY/8qvu7ruz9o9zjfVy5\n1mKtizOo3swvWI8FQS3zgP2x5mRPnWULZR2HtQLKv5tJkeeNdjhNcetciwXfRuB/sJob7JCiAwuo\nh7Hmc1wTyspT/h3OAO7Evo+NWA1e63/r812UGBFzSkOzgX0Hdpz1iRrLrMH20gVvcPN8vAKMjDzf\no+z1m4CPuPnLgIsrrONpik3jgiluftJ+itXghePbU6n/HdRrxo3GasV5WGtol9qLv+Y5bCfQGZn3\nBuy4OO62y1tqT2G/h91cOXbBPudb3evrsGb5JOArwIXE7wlf68oXLWvBMOA67DBkd7fdGynW1JU+\nh893UWKnmFMFk7FDiUewHdy/lb3+79j/dtfIvNnYIeIy7DdeU7OB/SJwGtZcOxILup2wvefZbpkr\nsWPQwjH2afifIrkfO36ajH0ZsyOv7e7KMAr7wW7CmsflfovtrY/GWkqfBt6C7b0LkuqdHY114Gx2\n2/yXstfXYR1ijTgfqwGPA36D1ZC1FD5bL3aYcYYr1xSsCf3zBra9DtsxFNa5Ftu5ngu8Dvt9TaXY\nmXcUsKd7/AIWcH2RddX67FdjAVA4xo52Sg51U+GwcAalP/512M5m58i8et9FXU00xXuw//X+wHux\nfox93WuTgcMobUnth/1O98P6tS6kTuy24nTXuViv9rex3tW/AcdjnShgp8HuBR50071uXkGtWqG8\n4+H32HHsg1iv9q8jrw/C/llPY82xD1D8sqLr2QAcju0VnwNOcs+jpyT6yx7XK2Ot51EnYX0OL2HH\ndFeVLT8H6/neCPxjjW0X5h2J/YALn/MbWKfQ0THL+3VsB/gE1rm4EOtfKCxXr8a+xv3dgH2vAF/E\ngmwp9j+9hmLL6t1Yc/ll4FdYoK5yr82h9LOXuxjrHHzAbeu6SPleduu62m3zaLf+gmVYBfOEe30P\n6n8XdTVRYz+DVVJgrdBHKR4KnosdskQd6crfg/2/VmAdf1Wled5wOtaEHIw1I8+uvXhLzMc6z56l\n2Dxsh8lY7/Hu2I/nIuBHCW9zOHZqaRgWaL+itIWTtMFYAK4GPtamba7CArUXC4KaP/4m9V8Vc0HX\nc1gt1jqx72l/4EPYWY8TsY7Ad2E7oh9jO8SF7j3zsJbnddW2mVan3WDgJ8CHsRr2HuAGbM+VpAXY\nP6n8FE3SCk2v+7Em4H3AzST7ebcAh2JNzSHYefn3u7/tcAJWa7+uTdsD22l20aYLQho56V3FaOBa\n7H/VB5yCNcMLalW8NVsXaQX2NKw5sco9vwprbiQd2LdS2lnULs9Q7GmPNr2S/ryb3d+h2M60XVdA\n7Yn1Sp+BHR60U9taodUC+yE3xXj7dVifxi+xFmQndqgB9j+8DzgQq/wmR967J3U6e9MK7EmUnrpY\njX2AgaATu3DirjZsaxB2vnYqxV7gdjgPuxpv53oLtlg/1g/TC/yMymdFWqbaqaxplB4DVGiyd2BX\n5y3FDkfB9gXjI8tEm+I3AFdgx9+TsIuw7q5VtrQCO3OX2LVItOn1Shu214ddHDMG63jqwq6sS9Lh\nWB/GEre9djoY65l/PXaos4zSS4lbqongORj4PNYJXLgU9xTsuLkgGiNLsY7BpdhlwccTaFO8vGkx\nmdLzp3lU3vRqpxexU2HvJvnAPgi7im8m1oG3M9an8cWEtwsW1GAX9VyPVZyJBXYTx9i3Uf+MVPn5\n/TPdFEtat0PeizUnOrHjv09jzY28qtT0Sto4YKx7PALrlFlSffGWOQXbUe+FdQj/kfYE9UiKHXWj\nsNOAMQ51/YV8SWla292O3ei/COvUuYTkO5LAzgUegl2s8BR2scyCmu9ojUpNr9nA7xLc5gTsvPAg\nN10O/CHB7VXTrsOu8RSvnRiCnRq6KckNtqBXPDGZuf9VJDD9D9RfBoC325+2xlpaNbZI5oVcYyuw\nRTyldedWHApsEU+qsUVyKOTgCblsIkHbKW70bE+0GBU1HdiHDKf/lkqD5ohkzl7Ak7F7r4cEHNit\n6ILv79+7/kKVzNkAcxoajKaoY/npfm8E7OKrriber+0mv03frqmbKb1BqhEnQ/yY6N88qv5CACM3\n0ch6W0JNcRFPsWvsFARcNJGw7TQs7RJUl2pgd6V2IrBT283lNiHZDEllAq4W0w3skfWXSUantpvL\nbULjY0E2QYEtkkMBR0/ARRMJXDvSFHpSYIv4Cjh6Ai6aSOAC7hWPM4LKdGzsqOXAt5ItjkiG+A+h\nUi3Fz1FuXi+W+CGqoRQ/9WrstMb/Fgmff3u32jjzD2F58H5Wtnw0xc8kbCTWfaiR5bZejR0d/7uH\n4vjfIjI45rSjail+lgGPV1i+4RQ/9QK70vjfk6osKzKwtGY0w07qjzM/kdJRfOvGYb3NDtTxv0Xq\na77ruZlx5psaVzzW+N9zNhQfd41I84oykUasxBJweqoSPd3P21RHI+PMN5zip96tZEOAx7AsgGuw\ntCJHU9p55n3bZjOau21TwpfGjQSN3bbZf0S8BTtsxPzoejuwoaE3YJ1o5RZjaX7vc8/3w1L8TKPY\nefYmatTa9WrstMb/Fgmff1O8WoqfYVg22HFY5pYlwAw8UvykOtBCM1Rj510Gauyj4i3YcQ2NrLcl\ndOWZiK+AoyfgookELuDoCbhoIoHT3V0iORRw9ARcNJHADU+7ANUpsEV8qSkukkMBR0/ARRMJXMDR\nE3DRRAKnprhIDgUcPS0pWhqXd67sLx9koj2m7r02le2yYk46201NCpnsGpX3wBYZkAIezFCBLeIr\n4OgJuGgigQs4egIumkjg1CsukkMBR0/ARRMJXMDRE3DRRAIXcFM8ToofEalkeMxpR/OBdVjmj4Jp\n2GChS7CMO++JvNZQeh9QYIv4808YsADLiRf1feA/seQBp7nnUJreZzpwITHiVoEt4ss/xc+twMay\neWuBMe7xWIrjhjec3gfiHWPPBz4KPAu8NcbyIgNDa3uoTgZuA36AVbjvc/MnAndGlouVZitO0RZg\nYx1f1lAxRfKuWiaQB21q0CVYOt3rsXS684HDqixbN/VWnMC+FUscJiJRVXrFu95hU8HcK2KtbRqW\nrhosn9c897jh9D6gY2wRf/694pWsAA5xj/+eYjrdG4DPAEOBvYC9sd7zmnQeW8SX/3nsK7EgHoel\nqT4NOA64ALtn7FX3HDzS+0DLArs78rgTtdwlG54AnvR/u3/0HF1l/oFV5p/ppthaFNhdrVmNSFu9\n0U0Fixt7e8Dt3TjH2FcCtwP7YM2GYxItkUhW+F+g0pai1VOt2SAysAV8rXjAjQmRwAUcPQEXTSRw\nGvNMJIcCjp6AiyYSuICjJ+CiiQQu4OgJuGgiYetXr7hI/vQGHD0BF00kbApskRzaOmxozCW3JVqO\nShTYIp56B4d7kJ3ZwH77psaHqGiFi5Z/IZXtHtcxNZXtpqcn7QLU1RvwNaWZDWyRtG1XYIvkT2/A\n4RNuyUQCF3JTXGOeiXjqZXCsqYJKmUDmYEMLL3HTjMhrDWcCUY0t4mkrcU937aDSkN79wLluiopm\nApkE/B4b9KSv1gZUY4t46mVIrKmCSplAADoqzPPKBKLAFvHURFO8mq8DD2DJA8a6eROxJnpBrEwg\nCmwRTy0O7J9i44YfgOXxOqfGsu0aflhk4Kl2Hvu+7le4r3tTo6t7NvJ4HvBr99grE4gCW8RTtfPY\nB3SN5YCusa89nzd3fZzVTcBqaoBPUOwxvwG4AutUm0QLM4FMxnrvdseaABcBP4pTUpE8a+I8dnkm\nkNOxwfkPwGLsSeArbtnEMoH0ACcC9wOjgfuAm4FHY38MkRza5n+6q9KQ3vNrLJ9IJpBn3ATwChbQ\nE1FgywCXp2vFO4F3AHe1vigi2ZKXa8VHY3l7T8Bq7ojuyONOlJRPsmGVm/yEfK143MDeCbgO+Dnw\nyx1f7mpZgUTap5PSSuiWht6d9cDuwK6EWQr8MNniiGRH1o+xDwY+DzyI3XUCdrfJ75IqlEgWbAs4\nx0+cwL4NXXoqsoOsN8VFpIKsN8VFpIK8nO4SkQg1xUVySIEtkkMKbJEc2prx010iUoFqbJEcUmCL\n5JDOY4vkkM5jJ+CV0Rekst3jSCfr5enMTWW7c7kxle3arQlhC7kprmvARTy1OMXPf2OjEj0A/C8w\nJvJawyl+FNginrYyNNZUwQJgetm8m4D9gbcDj2PBDKUpfqYDFxIjbhXYIp5anOLnZor5uO7Cxg8H\nzxQ/mT3GFklbgsfYx2LBDDZw6J2R12Kl+FFgi3hKKLBPBbZhSQKqUYofkaRUO4+9pns5a7pX+Kxy\nFjAT+FBknlL8iLRTtfPY47v2ZXzXvq89/8vcRXFWNx34JpYhZEtkfmIpfkSkghan+JkNDMU60QDu\nwNL5JJbiR0QqyHqKn+HYgMvDsD3KryieYxMZsLJ+rfgW4FBgs1v+NuD97q/IgJWHa8U3u79DgcHA\n88kURyQ78nCt+CAsje46YDF2IC8yoDVxrXji4tbYfVhS7jHAIixZV3cyRRLJhqwfY0e9CPwGeDcl\ngR15qGybkhkrgSe83531Y+xx2PmzF4ARwGFQfnNwV4uLJdIOU91U8IeG3t3E6a7ExQnsCcCl2HH2\nIOByGv0PiORQ1pviDwHvTLogIlmT9aa4iFQQ8ukuBbaIJwW2SA4psEVySCl+RHJINbZIDimwRXIo\n6+exRaSCkM9ja1xxEU9N3t11Anbx18PuMcCu2NBIj2MJBMb6lk2BLeKpicD+O+DLwHuwzB+HYxet\nn4wF9j7YZdsn+5Yt3LaElJjL+alst/+Kmalst+Oz6XzeRmzd5n0TyFuwbB+F0UhvAT4JHIENcgh2\nf0Y3nsGtwBbx1LvdO3weBs7Amt5bsLHE7wXGY4OZ4P6O992AAlvEU+92717xZcDZ2HH0Jmx0ot6y\nZfqJMcxwNQpsEU/VArvvtlvp+3PdsT7nUxxy+AwsJ9c6YA/gGex26Wd9y6bAFvG0vadKjX1gl00F\n3/9epaV2xwL3DcA/AO8F9gK+hNXmXwJ+6Vs2BbaIp77epsLnWmA3LD3u8diwY9/Dsn78E5Yy91O+\nK1dgi/jyP8YG+GCFec8DH25mpQUKbBFfW8INn3BLJhK67WkXoDoFtogvBbZIDuUgsAdjV8asBj6W\nXHFEMqQn7QJUFzewT8Dydb0uwbKIZEv5tWIBiXN3157YtazzgI5kiyOSIdtjTimIU2OfB3wT2Dnh\nsohky5b6i6SlXo19OHbZ2xJUW4uUynCNfRB2j+hMYDhWa18GfLF0se7I406UbVOyYTmwwv/tGe4V\nP8VNYDeAn8QOQQ3KtinZtLebCn7X2NszHNjlvO8PFcmdHJzuAhu+5ZakCiKSOQGf7tKVZyK+ctQU\nF5GCgE93KbBFfKnGFskhBbZIDgUc2MoEIuKrJ+ZU2Vhs3LNHsRusDkQpfkQC0Btzqux84EZgX+Bt\n2FjjSvEjkjr/XvExwAewIYbBGvUv0sIUP6qxRXz53wSyF7AeWAD8BbgYGEULU/wosEV8+R9jDwHe\nCVzo/m5ix5pZKX4GhnS6YDsuSuf2gLX93v1G3iY0emNytePnp7phdXetd6520z3u+bXAbCy1j1L8\niKSq2r52QpdNBXfOLV/iGeAprJPscSxJwCNuUoofkVQ114j6OrAQGAqsBI7BBg1Vih+RVDV32+YD\nwHsqzFeKH5FUbU27ANUpsEV8BXxJqQJbxFdORlARkSiNoCKSQ2qKi+SQAlskh3JwjL0KeAk7qugB\npiVVIJHMyMHprn4sK8DzyRVFJGNy0hRX7i6RqICb4nFv2+wHfg/cC/xzcsURyZDmRlBJVNwa+2Bg\nLfB6bOiWZcCtSRVKJBNy0BRf6/6uB67HOs8igd0dWbQTZduULLi9ezu3dzcRnRkP7JHY7WQvY8O3\nfAQou8G0q8XFEkneQV1DOKirGALnzG2wmzvgY+w4gT0eq6ULyy/EhkYVGdgyfrrrSeCApAsikjkZ\nb4qLSCUBN8U1SqmIL//TXcOBu4D7sSwgZ7n5ygQikjr/ccW3AIdih7hvc4/fTwszgSiwRXz5BzbA\nZvd3KHbWaSOWCeRSN/9S4OO+RVNgi/hqLinfIKwpvg5YjA093LJMIOo8E/HVXK94H9YUHwMswprj\nUU1lAkm5xl6l7bbFivZvcmN3+7cJzV1J1jLdwJzIVNOLwG+Ad2G19B5uflOZQBTYA2K7K9u/yRe6\n279NQgnsLuoE9jiKPd4jgMOAJcANFDNwKhOISMZMwDrHBrnpcqwXfAnKBCKSNu8rVB7CsmyWe54W\nZQJpxeAJ3RSTdYtk2S3Ev6Opv3jGqp6R0OaBSjQqioiffuv3imMMtDnW1BQX8fZq2gWoSoEt4i3c\nu0AU2CLeQji1VpkCW8SbamyRHFKNLZJDqrFFcki94iI5pKa4SA6pKS6SQ6qxRXJINbZIDqnGFskh\n1dgiOaTTXSI5pBpbJIfCPcbWuOIi3poaWHw6sAxYDnyr1SVTjS3izbvGHgz8BBvf7GngHmyE0kdb\nUy4FtkgTvI+xp2GDva9yz68CjkSBLRIC7xp7EvBU5Plq4MCmixOhwBbx5n26yzt1T1wKbBFvc+Iu\n+HLZ86eByZHnk7FaW0QybAiWd6kTS6N7P7BvmgUSkdaYATyGdaLNTrksIiIiIiIiIiIiIiIiIiIi\nIiKN+X8fezOkDjnJUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113fc0290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "validation_set = df.loc[(df[\"p_ID\"] > 21) & (df[\"p_ID\"] < 27)]\n",
    "validationX = validation_set[train_feat]\n",
    "validationY = validation_set['activity']\n",
    "print \"Mean accuracy score for the test set: \", rf.score(testX, testY)\n",
    "print \"Mean accuracy score for validation set: \", rf.score(\n",
    "    validationX, validationY)\n",
    "\n",
    "test_pred = rf.predict(testX)\n",
    "test_cm = skm.confusion_matrix(testY, test_pred)\n",
    "\n",
    "pl.matshow(test_cm)\n",
    "pl.title('Confusion matrix for test data')\n",
    "pl.colorbar()\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.853964\n",
      "Accuracy: 0.841065\n",
      "Recall: 0.841065\n",
      "F1: 0.840802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/metrics/classification.py:1082: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Library/Python/2.7/site-packages/sklearn/metrics/classification.py:1172: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Library/Python/2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "# Precision score\n",
    "print \"Precision: %f\" % (skm.precision_score(testY, test_pred))\n",
    "# Accuracy score\n",
    "print \"Accuracy: %f\" % (skm.accuracy_score(testY, test_pred))\n",
    "# Recall score\n",
    "print \"Recall: %f\" % (skm.recall_score(testY, test_pred))\n",
    "# F1 score\n",
    "print \"F1: %f\" % (skm.f1_score(testY, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
